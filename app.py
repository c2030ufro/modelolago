import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(
    page_title="AnÃ¡lisis de Calidad del Agua - Lago Villarrica",
    page_icon="ðŸŒŠ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# TÃ­tulo principal
st.title("ðŸŒŠ Sistema de AnÃ¡lisis de Calidad del Agua")
st.subheader("Lago Villarrica - RegiÃ³n de la AraucanÃ­a")

# FunciÃ³n para cargar y preprocesar datos MEJORADA
@st.cache_data
def load_and_preprocess_data():
    """Carga y preprocesa los datos del CSV"""
    try:
        # Lista de posibles nombres de archivo CSV
        possible_files = [
            'Consolidado Entrenamiento  Tabla Fechas.csv',
            'Consolidado Entrenamiento - Tabla Completa (1).csv',
            'Consolidado Entrenamiento  Tabla Completa 1.csv',
            'data.csv',
            'dataset.csv'
        ]
        
        df = None
        used_file = None
        
        # Intentar cargar cada archivo posible
        for filename in possible_files:
            try:
                df = pd.read_csv(filename)
                used_file = filename
                st.success(f"âœ… Datos cargados desde: {filename}")
                break
            except FileNotFoundError:
                continue
            except Exception as e:
                st.warning(f"âš ï¸ Error con {filename}: {e}")
                continue
        
        if df is None:
            st.error("âŒ No se encontrÃ³ ningÃºn archivo CSV vÃ¡lido. Archivos esperados:")
            for f in possible_files:
                st.write(f"   - {f}")
            return None
        
        # Limpiar nombres de columnas
        df.columns = df.columns.str.strip()
        
        # Mostrar informaciÃ³n del archivo cargado
        st.info(f"ðŸ“Š Archivo cargado: {used_file} ({len(df)} filas, {len(df.columns)} columnas)")
        
        # Identificar columnas que pueden tener valores numÃ©ricos con comas
        # Convertir TODAS las columnas excepto las claramente categÃ³ricas
        categorical_cols = ['DÃ­a', 'Folio', 'Lugar Muestreo', 'Comuna']
        
        for col in df.columns:
            if col not in categorical_cols:
                # Intentar convertir a numÃ©rico, reemplazando comas por puntos
                df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')
        
        # Procesar fechas si existe la columna DÃ­a
        if 'DÃ­a' in df.columns:
            try:
                # Intentar diferentes formatos de fecha
                df['Fecha'] = pd.to_datetime(df['DÃ­a'], errors='coerce', dayfirst=True)
                
                # Verificar si hay fechas vÃ¡lidas
                valid_dates = df['Fecha'].notna().sum()
                total_dates = len(df)
                
                if valid_dates > 0:
                    # Solo crear campos derivados si hay fechas vÃ¡lidas
                    df['DÃ­a_Semana'] = df['Fecha'].dt.day_name()
                    df['Mes'] = df['Fecha'].dt.month_name()
                    df['DÃ­a_Mes'] = df['Fecha'].dt.day
                    df['Semana'] = df['Fecha'].dt.isocalendar().week
                    st.success(f"âœ… Fechas procesadas: {valid_dates}/{total_dates} vÃ¡lidas")
                    
                    # Mostrar ejemplos de fechas procesadas
                    sample_dates = df[df['Fecha'].notna()]['Fecha'].head(3)
                    st.info(f"ðŸ“… Ejemplos de fechas: {', '.join([d.strftime('%d/%m/%Y') for d in sample_dates])}")
                else:
                    st.warning("âš ï¸ No se pudieron procesar fechas vÃ¡lidas")
                    df['Fecha'] = None
                    
            except Exception as e:
                st.warning(f"âš ï¸ Error procesando fechas: {e}")
                df['Fecha'] = None
        
        # Limpiar nombres de lugares y comunas
        df['Lugar Muestreo'] = df['Lugar Muestreo'].str.strip().str.title()
        df['Comuna'] = df['Comuna'].str.strip().str.title()
        
        # Crear variables categÃ³ricas con labels descriptivos
        viento_labels = {0: 'Sin viento', 1: 'Viento leve', 2: 'Viento moderado', 3: 'Viento fuerte'}
        oleaje_labels = {0: 'Sin oleaje', 1: 'Oleaje leve', 2: 'Oleaje moderado', 3: 'Oleaje fuerte'}
        musgo_labels = {0: 'Sin musgo', 1: 'Musgo verde', 2: 'Musgo pardo', 3: 'Ambos tipos'}
        algas_labels = {0: 'Sin algas', 1: 'Pocas algas', 2: 'Moderadas algas', 3: 'Muchas algas'}
        cielo_labels = {0: 'Soleado', 1: 'Parcial', 2: 'Nublado'}
        
        df['Viento_Label'] = df['Viento'].map(viento_labels)
        df['Oleaje_Label'] = df['Oleaje'].map(oleaje_labels)
        df['Musgo_Label'] = df['Musgo'].map(musgo_labels)
        df['Algas_Label'] = df['Algas'].map(algas_labels)
        df['Cielo_Label'] = df['Cielo'].map(cielo_labels)
        
        return df
    except Exception as e:
        st.error(f"Error cargando datos: {e}")
        return None

# FunciÃ³n para generar insights avanzados
def generate_advanced_insights(df, target_var):
    """Genera insights avanzados basados en rangos y correlaciones"""
    insights = []
    
    # Obtener variables numÃ©ricas
    numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
    numeric_vars = [col for col in numeric_vars if col != target_var and col in df.columns]
    
    if target_var not in df.columns:
        return insights
    
    for var in numeric_vars[:8]:  # Limitar a 8 variables para evitar sobrecarga
        try:
            # Calcular correlaciÃ³n
            correlation = df[var].corr(df[target_var])
            
            if abs(correlation) > 0.1:  # Solo mostrar correlaciones significativas
                # Dividir en rangos (cuartiles)
                quartiles = df[var].quantile([0.25, 0.5, 0.75]).values
                
                # Analizar cada rango
                for i, (q_low, q_high) in enumerate(zip([df[var].min()] + quartiles.tolist(), 
                                                       quartiles.tolist() + [df[var].max()])):
                    
                    mask = (df[var] >= q_low) & (df[var] <= q_high)
                    if mask.sum() > 5:  # Al menos 5 observaciones
                        target_values = df[mask][target_var]
                        
                        if target_var == 'Algas':
                            # Para algas (categÃ³rica), calcular probabilidad
                            prob = (target_values > 0).mean() * 100
                            if prob > 0:
                                range_name = f"{q_low:.2f} - {q_high:.2f}"
                                insights.append({
                                    'tipo': 'rango_algas',
                                    'variable': var,
                                    'rango': range_name,
                                    'probabilidad': prob,
                                    'n_muestras': mask.sum(),
                                    'descripcion': f"Cuando {var} estÃ¡ entre {range_name}, hay {prob:.1f}% probabilidad de presencia de algas ({mask.sum()} muestras)"
                                })
                        
                        elif target_var == 'FÃ³sforo reactivo total (mg/L)':
                            # Para fÃ³sforo (numÃ©rica), calcular promedio y rango
                            avg_val = target_values.mean()
                            std_val = target_values.std()
                            if not np.isnan(avg_val) and avg_val > 0:
                                range_name = f"{q_low:.2f} - {q_high:.2f}"
                                insights.append({
                                    'tipo': 'rango_fosforo',
                                    'variable': var,
                                    'rango': range_name,
                                    'promedio': avg_val,
                                    'desviacion': std_val,
                                    'n_muestras': mask.sum(),
                                    'descripcion': f"Cuando {var} estÃ¡ entre {range_name}, fÃ³sforo promedio: {avg_val:.4f} mg/L Â± {std_val:.4f} ({mask.sum()} muestras)"
                                })
        
        except Exception as e:
            continue
    
    return insights

# FunciÃ³n para detectar factores de riesgo
def detect_risk_factors(df):
    """Detecta factores de riesgo automÃ¡ticamente"""
    risk_factors = []
    
    # Definir umbrales de riesgo
    risk_conditions = [
        ('FÃ³sforo reactivo total (mg/L)', '>', 0.02, 'Alto fÃ³sforo'),
        ('pH', '>', 8.5, 'pH muy alcalino'),
        ('pH', '<', 6.5, 'pH muy Ã¡cido'),
        ('Temp Agua (Â°C)', '>', 25, 'Temperatura alta del agua'),
        ('Turb (FNU)', '>', 2, 'Alta turbidez'),
        ('Algas', '>', 1, 'Presencia significativa de algas')
    ]
    
    for var, operator, threshold, description in risk_conditions:
        if var in df.columns:
            try:
                if operator == '>':
                    risk_mask = df[var] > threshold
                else:
                    risk_mask = df[var] < threshold
                
                risk_percentage = (risk_mask.sum() / len(df)) * 100
                
                if risk_percentage > 5:  # Solo mostrar si afecta mÃ¡s del 5%
                    risk_factors.append({
                        'factor': description,
                        'variable': var,
                        'threshold': threshold,
                        'percentage': risk_percentage,
                        'count': risk_mask.sum(),
                        'operator': operator
                    })
            except:
                continue
    
    return sorted(risk_factors, key=lambda x: x['percentage'], reverse=True)

# Cargar datos
df = load_and_preprocess_data()

if df is not None:
    # Sidebar para navegaciÃ³n
    st.sidebar.title("ðŸ”§ Panel de Control")
    seccion = st.sidebar.selectbox(
        "Selecciona una secciÃ³n:",
        ["ðŸ“Š ExploraciÃ³n de Datos", "ðŸ“ˆ AnÃ¡lisis Temporal", "ðŸ” Insights Avanzados", "ðŸ¤– Modelos Predictivos"]
    )
    
    # SECCIÃ“N 1: EXPLORACIÃ“N DE DATOS
    if seccion == "ðŸ“Š ExploraciÃ³n de Datos":
        st.header("ðŸ“Š ExploraciÃ³n de Datos")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total de Muestras", len(df))
        with col2:
            st.metric("Playas Monitoreadas", df['Lugar Muestreo'].nunique())
        with col3:
            st.metric("Comunas", df['Comuna'].nunique())
        with col4:
            if 'Fecha' in df.columns:
                date_range = (df['Fecha'].max() - df['Fecha'].min()).days
                st.metric("DÃ­as de Monitoreo", date_range)
        
        # Mostrar informaciÃ³n temporal si existe
        if 'Fecha' in df.columns:
            st.subheader("ðŸ“… InformaciÃ³n Temporal")
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Fecha inicial:** {df['Fecha'].min().strftime('%d/%m/%Y')}")
                st.write(f"**Fecha final:** {df['Fecha'].max().strftime('%d/%m/%Y')}")
            with col2:
                st.write(f"**Muestras por dÃ­a:** {len(df) / date_range:.1f}")
                st.write(f"**DÃ­as con muestras:** {df['Fecha'].nunique()}")
        
        # Mostrar datos
        st.subheader("ðŸ“‹ Datos Cargados")
        st.dataframe(df.head(10))
        
        # EstadÃ­sticas descriptivas
        st.subheader("ðŸ“ˆ EstadÃ­sticas Descriptivas")
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        st.dataframe(df[numeric_cols].describe())
    
    # SECCIÃ“N 2: ANÃLISIS TEMPORAL
    elif seccion == "ðŸ“ˆ AnÃ¡lisis Temporal":
        st.header("ðŸ“ˆ AnÃ¡lisis Temporal")
        
        # Verificar si hay fechas vÃ¡lidas
        if 'Fecha' not in df.columns or df['Fecha'].notna().sum() == 0:
            st.error("âŒ No se encontrÃ³ informaciÃ³n de fechas vÃ¡lidas en los datos")
            st.info("ðŸ“‹ Para usar anÃ¡lisis temporal, asegÃºrate de que:")
            st.write("   - La columna 'DÃ­a' contenga fechas vÃ¡lidas")
            st.write("   - El formato de fecha sea reconocible (dd/mm/aaaa, yyyy-mm-dd, etc.)")
        else:
            # Filtrar solo datos con fechas vÃ¡lidas
            df_temporal = df[df['Fecha'].notna()].copy()
            
            st.info(f"ðŸ“Š Datos temporales disponibles: {len(df_temporal)} de {len(df)} registros")
            
            # Obtener todas las variables disponibles
            numeric_vars = df_temporal.select_dtypes(include=[np.number]).columns.tolist()
            categorical_vars = df_temporal.select_dtypes(include=['object']).columns.tolist()
            
            # Remover variables que no queremos en las opciones
            numeric_vars = [v for v in numeric_vars if v not in ['DÃ­a_Mes', 'Semana']]
            categorical_vars = [v for v in categorical_vars if v not in ['Folio', 'DÃ­a']]
            
            st.subheader("ðŸŽ¯ ConfiguraciÃ³n de AnÃ¡lisis Temporal")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**SelecciÃ³n de Variables**")
                variable_y = st.selectbox("Variable a analizar:", numeric_vars)
                
                # OpciÃ³n de agrupaciÃ³n temporal
                time_grouping = st.selectbox(
                    "AgrupaciÃ³n temporal:",
                    ["Sin agrupar", "Por dÃ­a", "Por semana", "Por mes", "Por lugar", "Por comuna"]
                )
                
                # Filtros adicionales
                filter_by = st.selectbox("Filtrar por:", ["Ninguno"] + categorical_vars)
                
            with col2:
                st.write("**Opciones de VisualizaciÃ³n**")
                chart_type = st.selectbox(
                    "Tipo de grÃ¡fico:",
                    ["LÃ­nea Temporal", "DispersiÃ³n Temporal", "Box Plot Temporal", 
                     "Histograma por PerÃ­odo", "Tendencia con RegresiÃ³n"]
                )
                
                # Variables adicionales
                color_by = st.selectbox("Colorear por:", ["Ninguno"] + categorical_vars)
                if len(numeric_vars) > 1:
                    size_options = ["Ninguno"] + [v for v in numeric_vars if v != variable_y]
                    size_by = st.selectbox("TamaÃ±o por:", size_options)
                else:
                    size_by = "Ninguno"
            
            # Aplicar filtros si se seleccionaron
            filtered_df = df_temporal.copy()
            if filter_by != "Ninguno" and filter_by in filtered_df.columns:
                available_values = filtered_df[filter_by].dropna().unique()
                if len(available_values) > 0:
                    filter_values = st.multiselect(
                        f"Valores de {filter_by}:",
                        available_values,
                        default=available_values
                    )
                    filtered_df = filtered_df[filtered_df[filter_by].isin(filter_values)]
            
            if len(filtered_df) == 0:
                st.error("âŒ No hay datos despuÃ©s del filtrado")
            else:
                # Generar grÃ¡fico temporal
                st.subheader(f"ðŸ“Š {chart_type}: {variable_y}")
                
                try:
                    fig = None
                    
                    if chart_type == "LÃ­nea Temporal":
                        if time_grouping == "Por dÃ­a":
                            daily_data = filtered_df.groupby(filtered_df['Fecha'].dt.date)[variable_y].mean().reset_index()
                            daily_data['Fecha'] = pd.to_datetime(daily_data['Fecha'])
                            fig = px.line(daily_data, x='Fecha', y=variable_y,
                                        title=f"EvoluciÃ³n Diaria Promedio de {variable_y}",
                                        template="plotly_white")
                        elif time_grouping == "Por semana":
                            weekly_data = filtered_df.groupby('Semana')[variable_y].mean().reset_index()
                            fig = px.line(weekly_data, x='Semana', y=variable_y,
                                        title=f"EvoluciÃ³n Semanal Promedio de {variable_y}",
                                        template="plotly_white")
                        elif time_grouping == "Por mes" and 'Mes' in filtered_df.columns:
                            monthly_data = filtered_df.groupby('Mes')[variable_y].mean().reset_index()
                            fig = px.line(monthly_data, x='Mes', y=variable_y,
                                        title=f"EvoluciÃ³n Mensual Promedio de {variable_y}",
                                        template="plotly_white")
                        else:
                            # Sin agrupar
                            fig = px.line(filtered_df.sort_values('Fecha'), x='Fecha', y=variable_y,
                                        color=color_by if color_by != "Ninguno" else None,
                                        title=f"EvoluciÃ³n Temporal de {variable_y}",
                                        template="plotly_white")
                        
                    elif chart_type == "DispersiÃ³n Temporal":
                        fig = px.scatter(filtered_df, x='Fecha', y=variable_y,
                                       color=color_by if color_by != "Ninguno" else None,
                                       size=size_by if size_by != "Ninguno" else None,
                                       title=f"DispersiÃ³n Temporal de {variable_y}",
                                       template="plotly_white")
                    
                    elif chart_type == "Box Plot Temporal":
                        if 'Mes' in filtered_df.columns and filtered_df['Mes'].notna().sum() > 0:
                            fig = px.box(filtered_df, x='Mes', y=variable_y,
                                       color=color_by if color_by != "Ninguno" else None,
                                       title=f"DistribuciÃ³n Mensual de {variable_y}",
                                       template="plotly_white")
                        elif 'DÃ­a_Semana' in filtered_df.columns:
                            fig = px.box(filtered_df, x='DÃ­a_Semana', y=variable_y,
                                       color=color_by if color_by != "Ninguno" else None,
                                       title=f"DistribuciÃ³n por DÃ­a de la Semana de {variable_y}",
                                       template="plotly_white")
                        else:
                            # Fallback: agrupar por semana
                            fig = px.box(filtered_df, x='Semana', y=variable_y,
                                       title=f"DistribuciÃ³n Semanal de {variable_y}",
                                       template="plotly_white")
                    
                    elif chart_type == "Histograma por PerÃ­odo":
                        if 'Mes' in filtered_df.columns:
                            fig = px.histogram(filtered_df, x=variable_y, 
                                             color='Mes',
                                             title=f"DistribuciÃ³n de {variable_y} por Mes",
                                             template="plotly_white")
                        else:
                            fig = px.histogram(filtered_df, x=variable_y,
                                             title=f"DistribuciÃ³n de {variable_y}",
                                             template="plotly_white")
                    
                    elif chart_type == "Tendencia con RegresiÃ³n":
                        fig = px.scatter(filtered_df, x='Fecha', y=variable_y,
                                       color=color_by if color_by != "Ninguno" else None,
                                       trendline="ols",
                                       title=f"Tendencia de {variable_y} con RegresiÃ³n",
                                       template="plotly_white")
                    
                    if fig:
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Mostrar estadÃ­sticas temporales
                        st.subheader("ðŸ“Š EstadÃ­sticas Temporales")
                        col1, col2, col3 = st.columns(3)
                        
                        try:
                            with col1:
                                # Calcular tendencia
                                sorted_data = filtered_df.sort_values('Fecha')
                                if len(sorted_data) > 1:
                                    x_vals = np.arange(len(sorted_data))
                                    y_vals = sorted_data[variable_y].dropna()
                                    if len(y_vals) > 1:
                                        trend_slope = np.polyfit(x_vals[:len(y_vals)], y_vals, 1)[0]
                                        trend_direction = "ðŸ“ˆ Creciente" if trend_slope > 0 else "ðŸ“‰ Decreciente" if trend_slope < 0 else "âž¡ï¸ Estable"
                                        st.metric("Tendencia General", trend_direction)
                                    else:
                                        st.metric("Tendencia General", "No disponible")
                                else:
                                    st.metric("Tendencia General", "Datos insuficientes")
                            
                            with col2:
                                volatility = filtered_df[variable_y].std()
                                if not np.isnan(volatility):
                                    st.metric("Volatilidad (Desv. Est.)", f"{volatility:.4f}")
                                else:
                                    st.metric("Volatilidad", "No disponible")
                            
                            with col3:
                                if len(filtered_df) > 1:
                                    sorted_data = filtered_df.sort_values('Fecha')
                                    last_values = sorted_data[variable_y].dropna()
                                    if len(last_values) >= 2:
                                        last_value = last_values.iloc[-1]
                                        first_value = last_values.iloc[0]
                                        if first_value != 0:
                                            change = ((last_value - first_value) / first_value) * 100
                                            st.metric("Cambio Total", f"{change:.1f}%")
                                        else:
                                            st.metric("Cambio Total", "No calculable")
                                    else:
                                        st.metric("Cambio Total", "Datos insuficientes")
                                else:
                                    st.metric("Cambio Total", "Una sola muestra")
                        except Exception as e:
                            st.warning(f"Error calculando estadÃ­sticas: {e}")
                    else:
                        st.error("No se pudo generar el grÃ¡fico con los parÃ¡metros seleccionados")
                        
                except Exception as e:
                    st.error(f"Error generando grÃ¡fico: {e}")
                    st.write("Detalles del error para debugging:")
                    st.write(f"- Datos filtrados: {len(filtered_df)} filas")
                    st.write(f"- Variable Y: {variable_y}")
                    st.write(f"- Tipo de datos: {filtered_df[variable_y].dtype}")
                    st.write(f"- Valores nulos: {filtered_df[variable_y].isnull().sum()}")
                    
                    # Mostrar muestra de datos para debugging
                    if len(filtered_df) > 0:
                        st.write("Muestra de datos:")
                        st.dataframe(filtered_df[['Fecha', variable_y]].head())
    
    # SECCIÃ“N 3: INSIGHTS AVANZADOS
    elif seccion == "ðŸ” Insights Avanzados":
        st.header("ðŸ” Insights Avanzados")
        
        # Seleccionar variable objetivo para anÃ¡lisis
        target_options = ['Algas', 'FÃ³sforo reactivo total (mg/L)']
        target_variable = st.selectbox("Selecciona variable objetivo para anÃ¡lisis:", target_options)
        
        if st.button("ðŸ” Generar AnÃ¡lisis Avanzado"):
            with st.spinner("Analizando patrones y generando insights..."):
                
                # Generar insights por rangos
                insights = generate_advanced_insights(df, target_variable)
                
                st.subheader(f"ðŸ“Š AnÃ¡lisis de Rangos para {target_variable}")
                
                if insights:
                    # Organizar insights por tipo
                    if target_variable == 'Algas':
                        algas_insights = [i for i in insights if i['tipo'] == 'rango_algas']
                        
                        if algas_insights:
                            st.write("**ðŸŒ± Factores que Influyen en la Presencia de Algas:**")
                            
                            # Ordenar por probabilidad
                            algas_insights.sort(key=lambda x: x['probabilidad'], reverse=True)
                            
                            for insight in algas_insights[:10]:  # Top 10
                                prob = insight['probabilidad']
                                if prob > 50:
                                    st.error(f"âš ï¸ {insight['descripcion']}")
                                elif prob > 30:
                                    st.warning(f"ðŸ”¶ {insight['descripcion']}")
                                else:
                                    st.info(f"â„¹ï¸ {insight['descripcion']}")
                    
                    elif target_variable == 'FÃ³sforo reactivo total (mg/L)':
                        fosforo_insights = [i for i in insights if i['tipo'] == 'rango_fosforo']
                        
                        if fosforo_insights:
                            st.write("**ðŸ§ª Factores que Influyen en la ConcentraciÃ³n de FÃ³sforo:**")
                            
                            # Ordenar por concentraciÃ³n promedio
                            fosforo_insights.sort(key=lambda x: x['promedio'], reverse=True)
                            
                            for insight in fosforo_insights[:10]:  # Top 10
                                conc = insight['promedio']
                                if conc > 0.02:
                                    st.error(f"âš ï¸ {insight['descripcion']}")
                                elif conc > 0.01:
                                    st.warning(f"ðŸ”¶ {insight['descripcion']}")
                                else:
                                    st.info(f"â„¹ï¸ {insight['descripcion']}")
                
                # Detectar factores de riesgo
                st.subheader("âš ï¸ Factores de Riesgo Detectados")
                risk_factors = detect_risk_factors(df)
                
                if risk_factors:
                    for risk in risk_factors:
                        if risk['percentage'] > 30:
                            st.error(f"ðŸš¨ **{risk['factor']}**: {risk['percentage']:.1f}% de las muestras ({risk['count']}/{len(df)})")
                        elif risk['percentage'] > 15:
                            st.warning(f"âš ï¸ **{risk['factor']}**: {risk['percentage']:.1f}% de las muestras ({risk['count']}/{len(df)})")
                        else:
                            st.info(f"â„¹ï¸ **{risk['factor']}**: {risk['percentage']:.1f}% de las muestras ({risk['count']}/{len(df)})")
                else:
                    st.success("âœ… No se detectaron factores de riesgo significativos")
                
                # AnÃ¡lisis de correlaciones temporales
                if 'Fecha' in df.columns:
                    st.subheader("ðŸ“ˆ AnÃ¡lisis de Tendencias Temporales")
                    
                    numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
                    
                    trends = {}
                    for var in numeric_vars[:8]:  # Limitar a 8 variables
                        try:
                            # Calcular tendencia temporal
                            df_temp = df.dropna(subset=[var, 'Fecha']).sort_values('Fecha')
                            if len(df_temp) > 5:
                                x_numeric = np.arange(len(df_temp))
                                slope, intercept = np.polyfit(x_numeric, df_temp[var], 1)
                                
                                # Clasificar tendencia
                                if abs(slope) < 0.01:
                                    trend_type = "Estable"
                                    emoji = "âž¡ï¸"
                                elif slope > 0:
                                    trend_type = "Creciente"
                                    emoji = "ðŸ“ˆ"
                                else:
                                    trend_type = "Decreciente"
                                    emoji = "ðŸ“‰"
                                
                                trends[var] = {
                                    'slope': slope,
                                    'type': trend_type,
                                    'emoji': emoji
                                }
                        except:
                            continue
                    
                    if trends:
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write("**Tendencias Crecientes:**")
                            growing = {k: v for k, v in trends.items() if v['type'] == 'Creciente'}
                            for var, trend in sorted(growing.items(), key=lambda x: x[1]['slope'], reverse=True):
                                st.write(f"{trend['emoji']} {var}: +{trend['slope']:.4f}/dÃ­a")
                        
                        with col2:
                            st.write("**Tendencias Decrecientes:**")
                            declining = {k: v for k, v in trends.items() if v['type'] == 'Decreciente'}
                            for var, trend in sorted(declining.items(), key=lambda x: x[1]['slope']):
                                st.write(f"{trend['emoji']} {var}: {trend['slope']:.4f}/dÃ­a")
                
                # Recomendaciones automÃ¡ticas
                st.subheader("ðŸ’¡ Recomendaciones AutomÃ¡ticas")
                
                recommendations = []
                
                # Basadas en factores de riesgo
                high_risk_factors = [r for r in risk_factors if r['percentage'] > 20]
                if high_risk_factors:
                    recommendations.append(f"ðŸ” Monitorear de cerca: {', '.join([r['factor'] for r in high_risk_factors[:3]])}")
                
                # Basadas en correlaciones
                if target_variable == 'Algas' and insights:
                    high_prob_factors = [i for i in insights if i['tipo'] == 'rango_algas' and i['probabilidad'] > 40]
                    if high_prob_factors:
                        recommendations.append(f"ðŸŒ± Controlar variables crÃ­ticas para algas: {', '.join([i['variable'] for i in high_prob_factors[:3]])}")
                
                # Basadas en tendencias temporales
                if trends:
                    critical_trends = [var for var, trend in trends.items() if 
                                     var in ['FÃ³sforo reactivo total (mg/L)', 'Algas', 'pH'] and 
                                     trend['type'] in ['Creciente', 'Decreciente']]
                    if critical_trends:
                        recommendations.append(f"ðŸ“Š Investigar tendencias en: {', '.join(critical_trends[:3])}")
                
                if recommendations:
                    for rec in recommendations:
                        st.info(rec)
                else:
                    st.success("âœ… Las condiciones del agua se mantienen dentro de parÃ¡metros normales")
    
    # SECCIÃ“N 4: MODELOS PREDICTIVOS (Mantenido igual)
    elif seccion == "ðŸ¤– Modelos Predictivos":
        st.header("ðŸ¤– Modelos Predictivos")
        
        # PestaÃ±as para los dos modelos
        tab1, tab2 = st.tabs(["ðŸ§ª Predictor de FÃ³sforo", "ðŸŒ± Predictor de Algas"])
        
        # Preparar datos para modelos
        @st.cache_data
        def prepare_model_data():
            # Excluir Folio, Lugar Muestreo y variables temporales
            features_cols = ['Comuna', 'Temp. Amb (Â°C)', 'pH', 'ORP (mV)', 'O2 Sat (%)', 'O2 (ppm)',
                           'Cond (ÂµS/cm)', 'Cond Abs (ÂµS/cm)', 'TDS (ppm)', 'Turb (FNU)', 
                           'Temp Agua (Â°C)', 'PresiÃ³n (PSI)', 'Viento', 'Oleaje', 'Musgo', 'Cielo']
            
            # Verificar que todas las columnas existen
            missing_cols = [col for col in features_cols if col not in df.columns]
            if missing_cols:
                st.error(f"Columnas faltantes: {missing_cols}")
                return None, None
            
            model_df = df[features_cols + ['FÃ³sforo reactivo total (mg/L)', 'Algas']].copy()
            
            # Mostrar informaciÃ³n de debug
            st.write("ðŸ“‹ **Debug: InformaciÃ³n de los datos**")
            st.write(f"Filas antes de limpiar: {len(model_df)}")
            st.write(f"Valores nulos por columna:")
            null_counts = model_df.isnull().sum()
            for col, count in null_counts.items():
                if count > 0:
                    st.write(f"  - {col}: {count} valores nulos")
            
            # Remover filas con valores nulos
            model_df = model_df.dropna()
            st.write(f"Filas despuÃ©s de limpiar: {len(model_df)}")
            
            if len(model_df) < 10:
                st.error("âš ï¸ Muy pocas muestras vÃ¡lidas para entrenar modelos. Verifica los datos.")
                return None, None
            
            # Codificar Comuna
            le_comuna = LabelEncoder()
            model_df['Comuna_encoded'] = le_comuna.fit_transform(model_df['Comuna'])
            
            # Crear variable binaria para algas
            model_df['Algas_presente'] = (model_df['Algas'] > 0).astype(int)
            
            return model_df, le_comuna
        
        model_df, le_comuna = prepare_model_data()
        
        if model_df is None:
            st.error("âŒ No se pudieron preparar los datos para los modelos.")
        else:
            # MODELO DE FÃ“SFORO
            with tab1:
                st.subheader("ðŸ§ª PredicciÃ³n de ConcentraciÃ³n de FÃ³sforo")
                
                # Entrenar modelo de fÃ³sforo
                @st.cache_resource
                def train_phosphorus_model():
                    try:
                        feature_cols = ['Comuna_encoded', 'Temp. Amb (Â°C)', 'pH', 'ORP (mV)', 'O2 Sat (%)', 
                                      'O2 (ppm)', 'Cond (ÂµS/cm)', 'Cond Abs (ÂµS/cm)', 'TDS (ppm)', 
                                      'Turb (FNU)', 'Temp Agua (Â°C)', 'PresiÃ³n (PSI)', 'Viento', 'Oleaje', 
                                      'Musgo', 'Cielo']
                        
                        X = model_df[feature_cols]
                        y = model_df['FÃ³sforo reactivo total (mg/L)']
                        
                        # Verificar que no hay valores nulos ni infinitos
                        if X.isnull().any().any() or y.isnull().any():
                            raise ValueError("Hay valores nulos en los datos de entrenamiento")
                        
                        if not np.isfinite(X.values).all() or not np.isfinite(y.values).all():
                            raise ValueError("Hay valores infinitos en los datos de entrenamiento")
                        
                        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                        
                        # Random Forest
                        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
                        rf_model.fit(X_train, y_train)
                        
                        y_pred = rf_model.predict(X_test)
                        mse = mean_squared_error(y_test, y_pred)
                        r2 = r2_score(y_test, y_pred)
                        
                        return rf_model, mse, r2, feature_cols
                    
                    except Exception as e:
                        st.error(f"Error entrenando modelo de fÃ³sforo: {e}")
                        return None, None, None, None
                
                phos_model, phos_mse, phos_r2, phos_features = train_phosphorus_model()
                
                if phos_model is None:
                    st.error("âŒ No se pudo entrenar el modelo de fÃ³sforo.")
                else:
                    # Mostrar mÃ©tricas del modelo
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Error CuadrÃ¡tico Medio", f"{phos_mse:.6f}")
                    with col2:
                        st.metric("RÂ² Score", f"{phos_r2:.3f}")
                    
                    # Correlaciones estadÃ­sticas mejoradas
                    st.subheader("ðŸ“Š AnÃ¡lisis de Correlaciones con FÃ³sforo")
                    correlations = model_df[['FÃ³sforo reactivo total (mg/L)', 'Temp. Amb (Â°C)', 'pH', 
                                           'O2 Sat (%)', 'Turb (FNU)', 'Temp Agua (Â°C)', 'ORP (mV)']].corr()['FÃ³sforo reactivo total (mg/L)'].sort_values(key=abs, ascending=False)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("**Correlaciones Positivas:**")
                        positive_corr = correlations[correlations > 0.1]
                        for var, corr in positive_corr.items():
                            if var != 'FÃ³sforo reactivo total (mg/L)':
                                st.success(f"ðŸ“ˆ {var}: +{corr:.3f}")
                    
                    with col2:
                        st.write("**Correlaciones Negativas:**")
                        negative_corr = correlations[correlations < -0.1]
                        for var, corr in negative_corr.items():
                            if var != 'FÃ³sforo reactivo total (mg/L)':
                                st.info(f"ðŸ“‰ {var}: {corr:.3f}")
                    
                    # Predictor interactivo
                    st.subheader("ðŸ”® Hacer PredicciÃ³n")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.write("**Variables FÃ­sicas**")
                        temp_amb = st.slider("Temperatura Ambiente (Â°C)", 10.0, 30.0, 20.0)
                        temp_agua = st.slider("Temperatura Agua (Â°C)", 10.0, 30.0, 20.0)
                        presion = st.slider("PresiÃ³n (PSI)", 13.0, 15.0, 14.3)
                    
                    with col2:
                        st.write("**Variables QuÃ­micas**")
                        ph_val = st.slider("pH", 6.0, 9.0, 7.5)
                        orp_val = st.slider("ORP (mV)", 150, 300, 220)
                        o2_sat = st.slider("O2 SaturaciÃ³n (%)", 70, 120, 95)
                        o2_ppm = st.slider("O2 (ppm)", 6.0, 12.0, 8.5)
                        cond = st.slider("Conductividad (ÂµS/cm)", 40, 80, 60)
                        cond_abs = st.slider("Conductividad Abs (ÂµS/cm)", 40, 80, 55)
                        tds = st.slider("TDS (ppm)", 20, 50, 30)
                        turb = st.slider("Turbidez (FNU)", 0.0, 5.0, 0.5)
                    
                    with col3:
                        st.write("**Variables Observacionales**")
                        comuna_pred = st.selectbox("Comuna", ["PucÃ³n", "Villarrica"])
                        viento_pred = st.selectbox("Viento", [0, 1, 2, 3], format_func=lambda x: {0: 'Sin viento', 1: 'Leve', 2: 'Moderado', 3: 'Fuerte'}[x])
                        oleaje_pred = st.selectbox("Oleaje", [0, 1, 2, 3], format_func=lambda x: {0: 'Sin oleaje', 1: 'Leve', 2: 'Moderado', 3: 'Fuerte'}[x])
                        musgo_pred = st.selectbox("Musgo", [0, 1, 2, 3], format_func=lambda x: {0: 'Sin musgo', 1: 'Verde', 2: 'Pardo', 3: 'Ambos'}[x])
                        cielo_pred = st.selectbox("Cielo", [0, 1, 2], format_func=lambda x: {0: 'Soleado', 1: 'Parcial', 2: 'Nublado'}[x])
                    
                    if st.button("ðŸ”® Predecir ConcentraciÃ³n de FÃ³sforo"):
                        # Preparar datos para predicciÃ³n
                        comuna_encoded = le_comuna.transform([comuna_pred])[0]
                        input_data = np.array([[comuna_encoded, temp_amb, ph_val, orp_val, o2_sat, o2_ppm,
                                              cond, cond_abs, tds, turb, temp_agua, presion, 
                                              viento_pred, oleaje_pred, musgo_pred, cielo_pred]])
                        
                        prediction = phos_model.predict(input_data)[0]
                        
                        st.success(f"ðŸ§ª **ConcentraciÃ³n de FÃ³sforo Predicha: {prediction:.6f} mg/L**")
                        
                        if prediction > 0.02:
                            st.error("âš ï¸ ConcentraciÃ³n alta de fÃ³sforo detectada - Riesgo de eutrofizaciÃ³n")
                        elif prediction > 0.01:
                            st.warning("ðŸ”¶ ConcentraciÃ³n moderada de fÃ³sforo - Monitoreo recomendado")
                        elif prediction < 0:
                            st.info("â„¹ï¸ ConcentraciÃ³n muy baja o no detectable")
                        else:
                            st.success("âœ… ConcentraciÃ³n normal de fÃ³sforo")
            
            # MODELO DE ALGAS
            with tab2:
                st.subheader("ðŸŒ± PredicciÃ³n de Presencia de Algas")
                
                # Entrenar modelo de algas
                @st.cache_resource
                def train_algae_model():
                    try:
                        feature_cols = ['Comuna_encoded', 'Temp. Amb (Â°C)', 'pH', 'ORP (mV)', 'O2 Sat (%)', 
                                      'O2 (ppm)', 'Cond (ÂµS/cm)', 'Cond Abs (ÂµS/cm)', 'TDS (ppm)', 
                                      'Turb (FNU)', 'Temp Agua (Â°C)', 'PresiÃ³n (PSI)', 'Viento', 'Oleaje', 
                                      'Musgo', 'Cielo']
                        
                        X = model_df[feature_cols]
                        y = model_df['Algas_presente']
                        
                        # Verificar que no hay valores nulos ni infinitos
                        if X.isnull().any().any() or y.isnull().any():
                            raise ValueError("Hay valores nulos en los datos de entrenamiento")
                        
                        if not np.isfinite(X.values).all():
                            raise ValueError("Hay valores infinitos en los datos de entrenamiento")
                        
                        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                        
                        # Random Forest Classifier
                        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
                        rf_model.fit(X_train, y_train)
                        
                        y_pred = rf_model.predict(X_test)
                        accuracy = accuracy_score(y_test, y_pred)
                        
                        return rf_model, accuracy, feature_cols
                    
                    except Exception as e:
                        st.error(f"Error entrenando modelo de algas: {e}")
                        return None, None, None
                
                algae_model, algae_accuracy, algae_features = train_algae_model()
                
                if algae_model is None:
                    st.error("âŒ No se pudo entrenar el modelo de algas.")
                else:
                    # Mostrar mÃ©tricas del modelo
                    st.metric("PrecisiÃ³n del Modelo", f"{algae_accuracy:.3f}")
                    
                    # Correlaciones estadÃ­sticas mejoradas
                    st.subheader("ðŸ“Š AnÃ¡lisis de Correlaciones con Presencia de Algas")
                    correlations_algae = model_df[['Algas_presente', 'Temp. Amb (Â°C)', 'pH', 'O2 Sat (%)', 
                                                 'Turb (FNU)', 'FÃ³sforo reactivo total (mg/L)', 'Temp Agua (Â°C)']].corr()['Algas_presente'].sort_values(key=abs, ascending=False)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("**Factores que Favorecen Algas:**")
                        positive_corr = correlations_algae[correlations_algae > 0.1]
                        for var, corr in positive_corr.items():
                            if var != 'Algas_presente':
                                percentage = abs(corr) * 100
                                st.success(f"ðŸ“ˆ {var}: +{percentage:.1f}%")
                    
                    with col2:
                        st.write("**Factores que Inhiben Algas:**")
                        negative_corr = correlations_algae[correlations_algae < -0.1]
                        for var, corr in negative_corr.items():
                            if var != 'Algas_presente':
                                percentage = abs(corr) * 100
                                st.info(f"ðŸ“‰ {var}: -{percentage:.1f}%")
                    
                    # Predictor interactivo
                    st.subheader("ðŸ”® Hacer PredicciÃ³n")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.write("**Variables FÃ­sicas**")
                        temp_amb_a = st.slider("Temperatura Ambiente (Â°C)", 10.0, 30.0, 20.0, key="temp_amb_algae")
                        temp_agua_a = st.slider("Temperatura Agua (Â°C)", 10.0, 30.0, 20.0, key="temp_agua_algae")
                        presion_a = st.slider("PresiÃ³n (PSI)", 13.0, 15.0, 14.3, key="presion_algae")
                    
                    with col2:
                        st.write("**Variables QuÃ­micas**")
                        ph_val_a = st.slider("pH", 6.0, 9.0, 7.5, key="ph_algae")
                        orp_val_a = st.slider("ORP (mV)", 150, 300, 220, key="orp_algae")
                        o2_sat_a = st.slider("O2 SaturaciÃ³n (%)", 70, 120, 95, key="o2_sat_algae")
                        o2_ppm_a = st.slider("O2 (ppm)", 6.0, 12.0, 8.5, key="o2_ppm_algae")
                        cond_a = st.slider("Conductividad (ÂµS/cm)", 40, 80, 60, key="cond_algae")
                        cond_abs_a = st.slider("Conductividad Abs (ÂµS/cm)", 40, 80, 55, key="cond_abs_algae")
                        tds_a = st.slider("TDS (ppm)", 20, 50, 30, key="tds_algae")
                        turb_a = st.slider("Turbidez (FNU)", 0.0, 5.0, 0.5, key="turb_algae")
                    
                    with col3:
                        st.write("**Variables Observacionales**")
                        comuna_pred_a = st.selectbox("Comuna", ["PucÃ³n", "Villarrica"], key="comuna_algae")
                        viento_pred_a = st.selectbox("Viento", [0, 1, 2, 3], format_func=lambda x: {0: 'Sin viento', 1: 'Leve', 2: 'Moderado', 3: 'Fuerte'}[x], key="viento_algae")
                        oleaje_pred_a = st.selectbox("Oleaje", [0, 1, 2, 3], format_func=lambda x: {0: 'Sin oleaje', 1: 'Leve', 2: 'Moderado', 3: 'Fuerte'}[x], key="oleaje_algae")
                        musgo_pred_a = st.selectbox("Musgo", [0, 1, 2, 3], format_func=lambda x: {0: 'Sin musgo', 1: 'Verde', 2: 'Pardo', 3: 'Ambos'}[x], key="musgo_algae")
                        cielo_pred_a = st.selectbox("Cielo", [0, 1, 2], format_func=lambda x: {0: 'Soleado', 1: 'Parcial', 2: 'Nublado'}[x], key="cielo_algae")
                    
                    if st.button("ðŸ”® Predecir Presencia de Algas"):
                        # Preparar datos para predicciÃ³n
                        comuna_encoded_a = le_comuna.transform([comuna_pred_a])[0]
                        input_data_a = np.array([[comuna_encoded_a, temp_amb_a, ph_val_a, orp_val_a, o2_sat_a, o2_ppm_a,
                                                cond_a, cond_abs_a, tds_a, turb_a, temp_agua_a, presion_a, 
                                                viento_pred_a, oleaje_pred_a, musgo_pred_a, cielo_pred_a]])
                        
                        prediction_algae = algae_model.predict(input_data_a)[0]
                        probability = algae_model.predict_proba(input_data_a)[0]
                        
                        if prediction_algae == 1:
                            st.error(f"ðŸŒ± **PRESENCIA DE ALGAS DETECTADA** (Probabilidad: {probability[1]:.2%})")
                            st.warning("âš ï¸ Se recomienda monitoreo adicional del cuerpo de agua")
                            
                            # Recomendaciones especÃ­ficas
                            if temp_agua_a > 22:
                                st.info("ðŸŒ¡ï¸ Temperatura del agua elevada favorece el crecimiento de algas")
                            if ph_val_a > 8:
                                st.info("ðŸ§ª pH alcalino puede promover proliferaciÃ³n algal")
                                
                        else:
                            st.success(f"âœ… **NO SE DETECTA PRESENCIA DE ALGAS** (Probabilidad: {probability[0]:.2%})")
                            st.info("â„¹ï¸ Condiciones del agua aparentemente normales")

else:
    st.error("âŒ No se pudo cargar el archivo CSV.")
    st.info("ðŸ“ Archivos CSV esperados en el directorio raÃ­z:")
    st.write("   - Consolidado Entrenamiento  Tabla Fechas.csv")
    st.write("   - Consolidado Entrenamiento - Tabla Completa (1).csv")
    st.write("   - data.csv")
    st.write("   - dataset.csv")

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center'>
    <p><strong>ðŸŒŠ Sistema de Monitero  Calidad del Agua</strong></p>
    <p>RegiÃ³n de la AraucanÃ­a - Lagos PucÃ³n y Villarrica</p>
    <p><em>Desarrollado por BIOREN UFRO con el apoyo de Ciencia 2030/em></p>
</div>
""", unsafe_allow_html=True)